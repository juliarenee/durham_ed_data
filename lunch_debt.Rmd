---
title: "Unpaid Lunch Debt in Durham, NC"
author: "Julia Donheiser"
date: "11/2/2018"
output: pdf_document
urlcolor: blue
---

## Introduction
When families can’t afford to pay for student lunches, school districts foot the bill. But with major cuts to educational funding in North Carolina—where some schools don’t even have enough funds to pay for students’ textbooks—this means school districts can wrack up tens of thousands of dollars in debt. In Durham, students with five or more unpaid lunches only receive a juice and a sandwich instead of a hot lunch. This lends its way to “lunch shaming”, where students who can’t afford pay skip the meal altogether to avoid the embarrassment of eating a cold lunch. This is a major issue, since student performance in school is directly tied to access to quality food.

### Data Sources
* End-of-Year unpaid meal data from James Keaten, director of child nutrition services at DPS.
* All free/reduced price lunch data was obtained from \href{http://www.ncpublicschools.org/fbs/resources/data/}{ncpublicschools.org}
* 2010-11 through 2015-16 demographic data was obtained from the \href{https://nces.ed.gov/ccd/elsi/tableGenerator.aspx}{NCES ELSI table generator}, code 91803
* 2017-18 ADM data from ncpublicschools.org's \href{http://www.ncpublicschools.org/fbs/accounting/data/}{Average Daily Membership and Membership Last Day by School}
* 2016-17, 2017-18 demographic data from \href{https://www.dpsnc.net/site/Default.aspx?PageID=324}{Durham Public Schools}
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, echo = FALSE, message = FALSE)

library(readxl) # read spreadsheets
library(dplyr) # wrangling
library(ggplot2) # graphing
library(tidyr) # reshaping
library(stringr) # string manipulation
library(data.table) # working with tables
library(cowplot) # layout plots
library(pdftools) # pdf to data
library(knitr) # nice tables

# get all older files, .xls format
old.dat = list.files("./data") %>%
  grep("freereduced.xls$", ., value = TRUE)

# read files as table
dat = lapply(paste("./data/",old.dat,sep=""), function(x) read_xls(x))

# clean empty rows
head(dat[[1]])
colnames(dat[[1]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[1]] = dat[[1]][2:dim(dat[[1]])[1],]
head(dat[[2]])
colnames(dat[[2]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[2]] = dat[[2]][5:dim(dat[[2]])[1],]
head(dat[[3]])
colnames(dat[[3]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[3]] = dat[[3]][7:dim(dat[[3]])[1],]
head(dat[[4]])
colnames(dat[[4]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[4]] = dat[[4]][7:dim(dat[[4]])[1],]
head(dat[[5]])
colnames(dat[[5]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy","pct_needy_mlt")

# get newer files, .xlsx format
new.dat = list.files("./data") %>%
  grep("freereduced.xlsx$", ., value = TRUE)
dat2 = lapply(paste("./data/",new.dat,sep=""), function(x) read_xlsx(x))

# check for cleaning
head(dat2[[1]])
colnames(dat2[[1]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy","pct_needy_mlt")
head(dat2[[2]])
colnames(dat2[[2]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy")
head(dat2[[3]])
colnames(dat2[[3]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy")

# join all data
dat[6:8] = dat2

# transform to data frames
dat = lapply(dat, function(x) data.frame(x))

# remove totals (last row)
dat = lapply(dat, function(x) x[-nrow(x),])

# add id for year
yrs = c(old.dat, new.dat) %>% substr(., 0, 7) # get year to bind as column
for(i in 1:length(dat)) {
  dat[[i]]$year = yrs[i]
}

# merge
df = do.call(plyr::rbind.fill, dat)

# filter to durham county
df = df[grepl("Durham", df$lea_name, ignore.case = TRUE),]

# indicator for CEP data
df$cep = ifelse(is.na(df$cep), 0, 1)

# for reduced < 20, set to 20
df$reduced[grepl("less than", df$reduced, ignore.case = TRUE)] = 20

# recalculate percent needy
df[,c(5:7)] = lapply(df[,c(5:7)],as.numeric)
df$pct_free_reduced = (df$free + df$reduced)/df$adm

# only keep percent needy to avoid conflicting adm
df = df %>% select(c("school_no","school_name","year","pct_free_reduced","adm","cep","grade"))

# load lunch debt data
debt = read.csv("./data/meal_debt.csv")
debt = debt[1:nrow(debt)-1,1:10] # remove totals at bottom, only full year data
colnames(debt)[1:2] = c("school_no", "school_name")
colnames(debt)[3:9] = yrs # reform years
colnames(debt)[10] = "2017-18"

# reshape wide to long
debt = gather(debt, year, unpaid, 3:10)

# convert to integer
debt$unpaid = debt$unpaid %>%
  gsub("\\$","",.) %>%
  gsub("\\,","",.) %>%
  as.numeric()

# convert to factor for joining
df$school_no = as.factor(df$school_no)
debt$school_no = as.factor(debt$school_no)

# join unpaid lunch with free/reduced lunch data
df = left_join(debt, df, by = c("year","school_no"))

# dedupe school name cols
df = df %>% select(-c("school_name.y"))
colnames(df)[which(colnames(df)=="school_name.x")] = "school_name"

# add demographic data
dem = read.csv("./data/nces_demographics.csv")

# remove state, only NC
dem = dem[-c(2)]

# also remove summary rows
spchars = c("†","‡","–")
dem = dem[!grepl(paste(spchars,collapse="|"),dem$School.Name),]

# split to datasets by year
dem11 = dem[c(1, grep("2010\\.11",colnames(dem)))]
dem12 = dem[c(1, grep("2011\\.12",colnames(dem)))]
dem13 = dem[c(1, grep("2012\\.13",colnames(dem)))]
dem14 = dem[c(1, grep("2013\\.14",colnames(dem)))]
dem15 = dem[c(1, grep("2014\\.15",colnames(dem)))]
dem16 = dem[c(1, grep("2015\\.16",colnames(dem)))]

# vectorize
x = list(dem11, dem12, dem13, dem14, dem15, dem16)

# FUNCTION: reformat column names
changeNames = function(z) {
  newNames = colnames(z) %>%
    gsub("\\.+","\\_",.) %>%
    tolower() %>%
    gsub("\\_students.*","",.) %>%
    gsub("\\_public_school.*","",.)
  colnames(z) = newNames
  return(z)
}

# apply to dataframes
x = lapply(x, changeNames)

# add year as variable
for(i in 1:length(x)) {
  x[[i]]$year = yrs[i]
}

# merge to dataframe
dem = do.call(rbind, x)

# set non-numeric values
dem[dem==spchars[1]] = NA
dem[dem==spchars[2]] = NA
dem[dem==spchars[3]] = NA

# all vars as char
dem[,1:14] = lapply(dem[,1:14],as.character)

# set alternative zeros to 0
dem[dem=="=0"] = 0
dem[dem=="=000"] = 0

# filter to durham
dem = dem[grepl("Durham", dem$county_name, ignore.case = TRUE),]

# clean school num
dem$state_school_id[nchar(dem$state_school_id) > 3] = dem$state_school_id[nchar(dem$state_school_id) > 3] %>% substr(., nchar(.)-2, nchar(.))

# vars to numeric
dem[,c(2:10)] = lapply(dem[,c(2:10)],as.numeric)

# calculate percentages
dem$adm = dem$male + dem$female
dem$pct_amin = dem$american_indian_alaska_native/dem$adm
dem$pct_asian = dem$asian_or_asian_pacific_islander/dem$adm
dem$pct_hispanic = dem$hispanic/dem$adm
dem$pct_black = dem$black/dem$adm
dem$pct_haw_pac = dem$hawaiian_nat_pacific_isl/dem$adm
dem$pct_white = dem$white/dem$adm
dem$pct_multi = dem$two_or_more_races/dem$adm

# only keep relevent cols for merging
dem = dem[c(12:14,16:22)]

# change col name
colnames(dem)[which(colnames(dem)=="state_school_id")] = "school_no"

# download durham 16-17, 17-18 demographic data
dem.new = list.files("./data") %>%
  grep("durham_dem", ., value = TRUE)

dem.new = lapply(paste("./data/",dem.new,sep=""), function(x) read_xlsx(x, skip = 2))

# only keep relevent cols
# school code
# and percentages of race
keep = c(2,seq(6,30,4))
dem.new = lapply(dem.new, function(x) x[keep])

# change column names
dem.names = c("school_no",
              "pct_amin",
              "pct_asian",
              "pct_hispanic",
              "pct_black",
              "pct_haw_pac",
              "pct_white",
              "pct_multi")
colnames(dem.new[[1]]) = dem.names
colnames(dem.new[[2]]) = dem.names

# add year
dem.new[[1]]$year = "2016-17"
dem.new[[2]]$year = "2017-18"

# clean school num
dem.new[[1]]$school_no = dem.new[[1]]$school_no %>% substr(., 4, 6)
dem.new[[2]]$school_no = dem.new[[2]]$school_no %>% substr(., 4, 6)

# merge
dem = plyr::rbind.fill(dem, data.frame(dem.new[[1]]), data.frame(dem.new[[2]]))

# merge with df
df = left_join(df, dem, by=c("school_no","year"))

# normalize debt by adm
df$debt_per_student = df$unpaid/df$adm

# standardize locales
df$urban_centric_locale[grepl("City", df$urban_centric_locale)] = "City"
df$urban_centric_locale[grepl("Suburb", df$urban_centric_locale)] = "Suburb"
df$urban_centric_locale[grepl("Rural", df$urban_centric_locale)] = "Rural"

# fill missing years for locale
locales = df %>%
  filter(!is.na(urban_centric_locale)) %>%
  group_by(school_no, urban_centric_locale) %>%
  summarise(count = n()) %>%
  distinct()

# some schools have multiple classifications
# choose the classification with more years
mult.locales = which(table(locales$school_no) > 1) %>% names() # schools that have more than 1 locale in data
for(i in 1:length(mult.locales)) {
  ix = which(locales$school_no == mult.locales[i]) # indeces
  m = min(locales$count[ix[1]], locales$count[ix[2]]) # minimums
  locales = locales[-ix[m],] # remove
}

# locales as list
locales.list = locales$urban_centric_locale
names(locales.list) = locales$school_no

# impute locales
df$urban_centric_locale = locales.list[df$school_no]

# many schools started offering Pre-K
# ignore this for now since only interested in elementary, middle and high schools
# replace Pre-K with K for consistency
df$grade = df$grade %>%
  trimws(.) %>% # trim trailing white space
  gsub("Pre-K","K",.) %>% # replace Pre-K
  gsub("[[:blank:]]+\\-[[:blank:]]+","\\-",.) %>% # remove space between dashes
  gsub("[[:blank:]]+","-",.) %>% # add dash for consistency
  gsub("0","",.) # remove 0 before single digit grades

df$grade[df$grade=="K--6"] = "K-6"
  
# see schools with more than 1 grade entry
gradeBySchool = df %>%
  filter(!is.na(grade)) %>%
  select(school_no, grade) %>%
  distinct() %>%
  group_by(school_no) %>%
  mutate(occ = n()) %>%
  arrange(school_no)

# only 342 poses a problem, since it seems that they have migrated from elementary to middle school (or vice versa) at some point in time... leave out of analysis for now

# list of unique grades
grade.key = unique(df$grade) %>% sort(decreasing = TRUE)
names(grade.key) = grade.key
grade.key[1:2] = "Elementary"
grade.key[c(3:4,8)] = "High"
grade.key[c(5:6)] = "Middle"
grade.key[7] = "Middle and High"

# add schcool level based on clean grades
gradeBySchool$grade_clean = grade.key[gradeBySchool$grade]

# 342 is Lakewood Middle
# ignore weird grades in data, clearly a middle school
gradeBySchool$grade_clean[gradeBySchool$school_no == "342"] = "Middle"

# only unique vals
gradeBySchool = gradeBySchool %>% select(school_no, grade_clean) %>% unique()

# as list for easy replacement
grade_clean = gradeBySchool$grade_clean
names(grade_clean) = gradeBySchool$school_no

# merge with data
df$grade_clean = grade_clean[df$school_no]

# remove DPS hospital school since non-standard school
df = df[-which(df$school_name=="DPS Hospital School"),]

# remove 389, 700 since no longer active
# remove 353, housed in Durham Tech
df = df[-which(df$school_no %in% c(389, 700, 353)),]

# grab schools with CEP status at any point in time
cep.schools = df %>%
  group_by(school_no) %>%
  summarise(years_cep = sum(cep, na.rm = TRUE)) %>%
  filter(years_cep > 0)

# indicator for whether school has had CEP at any point in time
# as of current, CEP var is on a yearly basis
df$cep_long = 0
df$cep_long[df$school_no %in% cep.schools$school_no] = 1

# longitudinal as factor
df$cep_long = as.factor(df$cep_long)

# CEP status as factor
df$cep = as.factor(df$cep)

# free/reduced for CEP schools to 1 when > 1
df$pct_free_reduced[df$pct_free_reduced > 1] = 1

# remove data where no CEP/adm data
df = df[!is.na(df$adm),]

# add percent minority
df$pct_minority = df$pct_black + df$pct_hispanic
```

## Exploratory Data Analysis
```{r}
# debt over time, excluding non-standard and inactive schools
df %>%
  group_by(year) %>%
  summarise(total_debt = sum(unpaid, na.rm = TRUE),
            mean_debt_per_student = mean(debt_per_student, na.rm = TRUE),
            fullprice_lunches = total_debt/2.90)

# debt over time, all schools
```
At the end of the 2017-18 academic year, DPS had over \$209,000 in school lunch debt. That's over 72,000 unpaid lunches, with an average of \$5.10 of debt per student. It's also the most debt the school district has seen in the past eight years.

```{r, fig.width=5, fig.height=3, fig.align="center"}
# histogram
hist(df$debt_per_student, main = "", xlab = "debt-per-student")
```
Most schools have less than \$5 of lunch debt per student. In Durham, a full-priced lunch costs \$2.90, and a reduced-price lunch cost \$0.40, according to the Durham Public Schools \href{https://www.dpsnc.net/site/handlers/filedownload.ashx?moduleinstanceid=196&dataid=173&FileName=2018-19%20FR%20Lunch%20App_Eng.pdf}{website}. That's about two unpaid full-priced lunches per student, or just over 12 unpaid reduced-price lunches per student. For the rest of my EDA, I'll delve into which schools have more debt and whether we can find systematic issues. I'll also be looking at schools that are part of the Community Eligibility Provision, which means all students receive free lunch.

### Debt and Demographics
```{r, fig.width=12, fig.height=4, fig.align="center"}
# scatterplot of debt vs. pct needy
ggplot(df[df$cep == 0,], aes(pct_free_reduced, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("percent students with free and reduced lunch") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

# scatterplot of debt vs. pct black
g1 = ggplot(df[df$cep == 0,], aes(pct_black, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("Percent Black") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

# scatterplot of debt vs. pct hispanic
g2 = ggplot(df[df$cep == 0,], aes(pct_hispanic, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("Percent Hispanic") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

# scatterplot of debt vs. pct white
g3 = ggplot(df[df$cep == 0,], aes(pct_white, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("Percent White") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

plot_grid(g1, g2, g3, ncol = 3)

ggplot(df[df$cep == 0,], aes(pct_minority, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("Percent Minority") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

g1 = ggplot(df, aes(pct_white, pct_black)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent White") +
  ylab("Percent Black")

g2 = ggplot(df, aes(pct_white, pct_hispanic)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent White") +
  ylab("Percent Hispanic")

g3 = ggplot(df, aes(pct_black, pct_hispanic)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent Black") +
  ylab("Percent Hispanic")

plot_grid(g1, g2, g3, ncol = 3)

ggplot(df, aes(pct_minority, pct_white)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent Minority") +
  ylab("Percent White")
```

There is a weak positive correlation between the percentage of students who have free and reduced price lunch and the debt-per-student at each school. It looks like schools with CEP status generally have a higher percentage of students on free/reduced lunch. As for demographics, there is also a weak positive correlation between the percentage of black students and debt-per-student. Conversely, there is a weak negative correlation between the percent of white students and debt-per-student. There doesn't appear to be a much of a relationship between the percentage of hispanic students and debt-per-student. That being said, if we look at the total percentage of minority students --- the percentage of black \textit{and} hispanic students --- there is a positive correlation with debt-per-student. Schools that CEP status are also starkly segregated, with very few white students and primarily black and hispanic students.

### Debt over time
```{r debt_over_time, fig.width=8, fig.height=4}
# debt by school over time
p1 = ggplot(df, aes(year, unpaid, group = school_no, col = cep_long)) +
  geom_point() +
  geom_line() +
  ylab("total debt") +
  ggtitle("Total Debt by School") +
  scale_y_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12)) +
  facet_wrap(~ cep_long, nrow = 2)

# debt/student over time
p2 = ggplot(df, aes(year, debt_per_student, group = school_no, col = cep_long)) +
  geom_point() +
  geom_line() +
  ylab("debt per student") +
  ggtitle("Debt per Student by School") +
  scale_y_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12)) +
  facet_wrap(~ cep_long, nrow = 2)

plot_grid(p1, p2)
```

Schools with CEP status generally had a large amount of debt until the 2014-15 school year, when they gained CEP status. That being said, other schools with similar amounts of debt did not gain CEP status.

### Demographics and need
```{r, fig.width=12, fig.height=4, fig.align="center"}
g1 = ggplot(df[df$cep == 0,], aes(pct_white, pct_free_reduced)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent White") +
  ylab("percent students with free and reduced lunch")

g2 = ggplot(df[df$cep == 0,], aes(pct_hispanic, pct_free_reduced)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent Hispanic") +
  ylab("percent students with free and reduced lunch")

g3 = ggplot(df[df$cep == 0,], aes(pct_black, pct_free_reduced)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent Black") +
  ylab("percent students with free and reduced lunch")

g4 = ggplot(df[df$cep == 0,], aes(pct_minority, pct_free_reduced)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent Minority") +
  ylab("percent students with free and reduced lunch")

plot_grid(g1, g2, g3, g4, ncol = 4)
```

We can also see that race is a proxy for need. The percentage of black and hispanic schools have a strong, positive correlation with the percentage of students on free and reduced price lunch. For white students, this relationship is strong and negative.

### Locale and debt, race
```{r, fig.width=12, fig.height=4, fig.align="center"}
b1 = ggplot(df[df$cep == 0,], aes(urban_centric_locale, unpaid)) +
  geom_boxplot()

b2 = ggplot(df[df$cep == 0,], aes(urban_centric_locale, debt_per_student)) +
  geom_boxplot()

plot_grid(b1, b2, ncol = 2)
```
There don't seem to be major differences in debt by location.

```{r, fig.width=12, fig.height=4, fig.align="center"}
b1 = ggplot(df, aes(urban_centric_locale, pct_white)) +
  geom_boxplot() +
  ylim(c(0,1))

b2 = ggplot(df, aes(urban_centric_locale, pct_black)) +
  geom_boxplot() +
  ylim(c(0,1))

b3 = ggplot(df, aes(urban_centric_locale, pct_hispanic)) +
  geom_boxplot() +
  ylim(c(0,1))

b4 = ggplot(df, aes(urban_centric_locale, pct_minority)) +
  geom_boxplot() +
  ylim(c(0,1))

plot_grid(b1, b2, b3, b4, ncol = 4)
```
On average, we also don't see any major differences in race by locale. However, there is a subset of rural schools that seem to primarily be white.

### Debt and grade
```{r}
df %>%
  filter(cep == 0) %>%
  group_by(grade_clean) %>%
  summarise(mean_debt = mean(unpaid),
            mean_dps = mean(debt_per_student))
```
On average, high schools have the most total debt. However, middle schools, on average, have the most debt per student.

```{r, fig.width=12, fig.height=4, fig.align="center"}
b1 = ggplot(df[df$cep == 0,], aes(grade_clean, unpaid)) +
  geom_boxplot()

b2 = ggplot(df[df$cep == 0,], aes(grade_clean, debt_per_student)) +
  geom_boxplot()

plot_grid(b1, b2, ncol = 2)
```

### CEP Status and Grade Level
```{r}
df %>%
  select(school_no, cep_long, grade_clean) %>%
  distinct() %>%
  group_by(grade_clean) %>%
  summarise(cep_schools = sum(cep_long==1))
```
Most CEP schools are elementary schools. However, we're also seeing that the schools with the most debt are, on average, middle and high schools.

## Regression
### Predicting debt per student

I built four linear models to predict debt per student based on various combinations of the percentage of students on free/reduced price lunch, school level, locale and demographics. For these models, I excluded years where CEP schools had CEP status, since their debt would be zero.

```{r}
# predict debt by demographics
lm.dem.locale = lm(debt_per_student ~ pct_minority + grade_clean + urban_centric_locale, data = df[df$cep == 0,])
summary(lm.dem.locale)

# predict debt by demographics, exclude locale
lm.dem = lm(debt_per_student ~ pct_minority + urban_centric_locale, data = df[df$cep == 0,])
summary(lm.dem)

# predict debt by percent need
lm.need.locale = lm(debt_per_student ~ pct_free_reduced + grade_clean + urban_centric_locale, data = df[df$cep == 0,])
summary(lm.need.locale)

# predict debt by percent need, exclude locale
lm.need = lm(debt_per_student ~ pct_free_reduced + grade_clean, data = df[df$cep == 0,])
summary(lm.need)

anova(lm.dem.locale, lm.dem, lm.need.locale, lm.need)

# last model with just need and grade is best
# check residuals
plot(lm.need.locale$residuals)

# normally distributed around zero, but still a lot of noise
```
None of my models for predicting debt per student explained a large amount of the variance in the data, but I was able to single out the best of my models. The percentage of students who receive free or reduced price lunch is a major predictor of debt per student. For every one percent increase in students who receive free/reduced price lunch, the average debt per student increases by \$0.11. Based on our EDA, we also know that schools with a high percentage of free/reduced lunch students tend to be mostly black and hispanic. Our model also found that high schools have \$2.15 more debt per student than elementary schools. For middle schools, that value is \$1.33. This is interesting, since most CEP schools are actually elementary schools. It also appears that rural schools tend to have more debt per student than urban schools, and suburban schools have less debt per student.

### Predicting CEP schools

In this section of my analysis, I try to predict whether a school has CEP status or not. I do this using a logistic regression. The idea here is simple: If I can build a logistic regression model and choose a threshold that accurately predicts the CEP schools, the false positives are, in essence, schools that should also have CEP status. This is an important question: Why do some schools have CEP status while others don't? Especially if there are schools with similar levels of need and debt per student? For my model, I am excluding years where schools had CEP status, and my outcome is `cep_long`, or the longitudinal indicator of whether a school has gained CEP status at any point in time.

```{r}
# train data before cep years
df$ts = df$year %>% substr(., 0, 4) %>% as.numeric()
train = df[df$ts < 2015,]

# test data first year of cep status
test = df[df$ts == 2015,]

# debt per student, need, grade
logit.1 = glm(cep_long ~ debt_per_student + pct_free_reduced + grade_clean, data = train, family="binomial")
summary(logit.1)

# debt per student, race, grade
logit.2 = glm(cep_long ~ debt_per_student + pct_minority + grade_clean, data = train, family="binomial")
summary(logit.2)

# test for differences
anova(logit.1, logit.2)
```
I'll stick with my second model, since they are both roughly good predictors of whether a school gains CEP status.

```{r}
exp(logit.2$coefficients) %>% signif(., 3)
exp(logit.2$coefficients[3]/100) %>% signif(., 3)
```
For every additional dollar of debt per student, schools are 1.24 times more likely to receive CEP status. For every additional percentage point of minority students, schools are 1.56 times more likely to gain CEP status. We also see that high schools are 0.003 times less likely to be assigned CEP status. The intercept for middle schools is not significant.

### Predictions
```{r}
df$predict = predict.glm(logit.2, df, type = "response")
df$predict_ind = ifelse(df$predict > .5, 1, 0)
df %>%
  filter(ts == 2015) %>%
  select(school_no, school_name, debt_per_student, pct_free_reduced, grade_clean, cep, predict_ind) %>%
  filter(cep == 1 | predict_ind == 1) %>%
  mutate(diff = as.numeric(predict_ind) - as.numeric(cep))
```
Based on my model (which isn't the best out there), there are 6 schools that were not assigned CEP status even though they have similar assets.

## K-means models
In this section, I'll try to group the schools by high and low need through a k-means clustering algorithm.



NOTES:

- CEP provisions began in 2014-15 in NC
- data collected at different times so numbers won't match perfectly
- 353 is housed in Durham Tech, which complicates some of the data
- For the most part, aside from missing data, it seems like schools with no debt are CEP schools. We can't get CEP status starting in 2010-11, since those were pilot years.
- CEP schools for 2017-18 all have > 90% free/reduced, setting to 100% (doesn't affect analysis since excluded from regression)


REPORTING QUESTIONS:
- how do students get assigned to schools? any diversity initiatives?
- does the district track when debt is payed off?
- can a student graduate with debt? are they barred from anything? what are consequences besides food?