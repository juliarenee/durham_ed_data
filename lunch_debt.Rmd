---
title: "Unpaid Lunch Debt in Durham, NC"
author: "Julia Donheiser"
date: "11/2/2018"
output: pdf_document
urlcolor: blue
---

## Introduction
When families can’t afford to pay for student lunches, school districts foot the bill. But with major cuts to educational funding in North Carolina—where some schools don’t even have enough funds to pay for students’ textbooks—this means school districts can wrack up tens of thousands of dollars in debt. In Durham, students with five or more unpaid lunches only receive a juice and a sandwich instead of a hot lunch. This lends its way to “lunch shaming”, where students who can’t afford pay skip the meal altogether to avoid the embarrassment of eating a cold lunch. This is a major issue, since student performance in school is directly tied to access to quality food.

### Data Sources
* End-of-Year unpaid meal data from James Keaton, director of child nutrition services at DPS.
* All free/reduced price lunch data was obtained from \href{http://www.ncpublicschools.org/fbs/resources/data/}{ncpublicschools.org}
* 2010-11 through 2015-16 demographic data was obtained from the \href{https://nces.ed.gov/ccd/elsi/tableGenerator.aspx}{NCES ELSI table generator}, code 91803
* 2017-18 ADM data from ncpublicschools.org's \href{http://www.ncpublicschools.org/fbs/accounting/data/}{Average Daily Membership and Membership Last Day by School}
* 2016-17, 2017-18 demographic data from \href{https://www.dpsnc.net/site/Default.aspx?PageID=324}{Durham Public Schools}
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, echo = FALSE, message = FALSE)

library(readxl) # read spreadsheets
library(dplyr) # wrangling
library(ggplot2) # graphing
library(tidyr) # reshaping
library(stringr) # string manipulation
library(data.table) # working with tables
library(cowplot) # layout plots
library(pdftools) # pdf to data
library(knitr) # nice tables

# get all older files, .xls format
old.dat = list.files("./data") %>%
  grep("freereduced.xls$", ., value = TRUE)

# read files as table
dat = lapply(paste("./data/",old.dat,sep=""), function(x) read_xls(x))

# clean empty rows
head(dat[[1]])
colnames(dat[[1]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[1]] = dat[[1]][2:dim(dat[[1]])[1],]
head(dat[[2]])
colnames(dat[[2]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[2]] = dat[[2]][5:dim(dat[[2]])[1],]
head(dat[[3]])
colnames(dat[[3]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[3]] = dat[[3]][7:dim(dat[[3]])[1],]
head(dat[[4]])
colnames(dat[[4]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[4]] = dat[[4]][7:dim(dat[[4]])[1],]
head(dat[[5]])
colnames(dat[[5]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy","pct_needy_mlt")

# get newer files, .xlsx format
new.dat = list.files("./data") %>%
  grep("freereduced.xlsx$", ., value = TRUE)
dat2 = lapply(paste("./data/",new.dat,sep=""), function(x) read_xlsx(x))

# check for cleaning
head(dat2[[1]])
colnames(dat2[[1]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy","pct_needy_mlt")
head(dat2[[2]])
colnames(dat2[[2]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy")
head(dat2[[3]])
colnames(dat2[[3]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy")

# join all data
dat[6:8] = dat2

# transform to data frames
dat = lapply(dat, function(x) data.frame(x))

# remove totals (last row)
dat = lapply(dat, function(x) x[-nrow(x),])

# add id for year
yrs = c(old.dat, new.dat) %>% substr(., 0, 7) # get year to bind as column
for(i in 1:length(dat)) {
  dat[[i]]$year = yrs[i]
}

# merge
df = do.call(plyr::rbind.fill, dat)

# indicator for CEP data
df$cep = ifelse(is.na(df$cep), 0, 1)

# filter to durham county
df = df[grepl("Durham", df$lea_name, ignore.case = TRUE),]

# only keep percent needy to avoid conflicting adm
df.trimmed = df %>% select(c("school_no","school_name","year","pct_needy","cep","grade"))

# load lunch debt data
debt = read.csv("./data/meal_debt.csv")
debt = debt[1:nrow(debt)-1,1:10] # remove totals at bottom, only full year data
colnames(debt)[1:2] = c("school_no", "school_name")
colnames(debt)[3:9] = yrs # reform years
colnames(debt)[10] = "2017-18"

# reshape wide to long
debt = gather(debt, year, unpaid, 3:10)

# convert to integer
debt$unpaid = debt$unpaid %>%
  gsub("\\$","",.) %>%
  gsub("\\,","",.) %>%
  as.numeric()

# convert to factor for joining
df$school_no = as.factor(df$school_no)
debt$school_no = as.factor(debt$school_no)

# join unpaid lunch with free/reduced lunch data
df = left_join(debt, df.trimmed, by = c("year","school_no"))

# dedupe school name cols
df = df %>% select(-c("school_name.y"))
colnames(df)[which(colnames(df)=="school_name.x")] = "school_name"

# character to numeric
df$pct_needy = as.numeric(df$pct_needy)

# add demographic data
dem = read.csv("./data/nces_demographics.csv")

# remove state, only NC
dem = dem[-c(2)]

# also remove summary rows
spchars = c("†","‡","–")
dem = dem[!grepl(paste(spchars,collapse="|"),dem$School.Name),]

# split to datasets by year
dem11 = dem[c(1, grep("2010\\.11",colnames(dem)))]
dem12 = dem[c(1, grep("2011\\.12",colnames(dem)))]
dem13 = dem[c(1, grep("2012\\.13",colnames(dem)))]
dem14 = dem[c(1, grep("2013\\.14",colnames(dem)))]
dem15 = dem[c(1, grep("2014\\.15",colnames(dem)))]
dem16 = dem[c(1, grep("2015\\.16",colnames(dem)))]

# vectorize
x = list(dem11, dem12, dem13, dem14, dem15, dem16)

# FUNCTION: reformat column names
changeNames = function(z) {
  newNames = colnames(z) %>%
    gsub("\\.+","\\_",.) %>%
    tolower() %>%
    gsub("\\_students.*","",.) %>%
    gsub("\\_public_school.*","",.)
  colnames(z) = newNames
  return(z)
}

# apply to dataframes
x = lapply(x, changeNames)

# add year as variable
for(i in 1:length(x)) {
  x[[i]]$year = yrs[i]
}

# merge to dataframe
dem = do.call(rbind, x)

# set non-numeric values
dem[dem==spchars[1]] = NA
dem[dem==spchars[2]] = NA
dem[dem==spchars[3]] = NA

# all vars as char
dem[,1:14] = lapply(dem[,1:14],as.character)

# set alternative zeros to 0
dem[dem=="=0"] = 0
dem[dem=="=000"] = 0

# filter to durham
dem = dem[grepl("Durham", dem$county_name, ignore.case = TRUE),]

# clean school num
dem$state_school_id[nchar(dem$state_school_id) > 3] = dem$state_school_id[nchar(dem$state_school_id) > 3] %>% substr(., nchar(.)-2, nchar(.))

# vars to numeric
dem[,c(2:10)] = lapply(dem[,c(2:10)],as.numeric)

# calculate percentages
dem$adm = dem$male + dem$female
dem$pct_amin = dem$american_indian_alaska_native/dem$adm
dem$pct_asian = dem$asian_or_asian_pacific_islander/dem$adm
dem$pct_hispanic = dem$hispanic/dem$adm
dem$pct_black = dem$black/dem$adm
dem$pct_haw_pac = dem$hawaiian_nat_pacific_isl/dem$adm
dem$pct_white = dem$white/dem$adm
dem$pct_multi = dem$two_or_more_races/dem$adm

# only keep relevent cols for merging
dem = dem[c(12:14,16:22)]

# download durham 16-17, 17-18 demographic data
dem.new = list.files("./data") %>%
  grep("durham_dem", ., value = TRUE)

dem.new = lapply(paste("./data/",dem.new,sep=""), function(x) read_xlsx(x, skip = 2))

# only keep relevent cols
# school code
# and percentages of race
keep = c(2,seq(6,30,4))
dem.new = lapply(dem.new, function(x) x[keep])

# change column names
dem.names = c("school_no",
              "pct_amin",
              "pct_asian",
              "pct_hispanic",
              "pct_black",
              "pct_haw_pac",
              "pct_white",
              "pct_multi")
colnames(dem.new[[1]]) = dem.names
colnames(dem.new[[2]]) = dem.names

# add year
dem.new[[1]]$year = "2016-17"
dem.new[[2]]$year = "2017-18"

# merge
dem = plyr::rbind.fill(dem, data.frame(dem.new[[1]]), data.frame(dem.new[[2]]))

# merge with df
df = left_join(df, dem, by=c("school_no"="state_school_id","year"))

# remove empty col
df = df %>% select(-c("school_no.y"))

# see grades
grades = unique(df$grade)

# indicator for elementary school
df$elementary = ifelse(df$grade %in% grades[c(1,5,9,11,13,14,15,16,18)], 1, 0)
df$middle = ifelse(df$grade %in% grades[c(2,4,5,10,14,16,17)],1,0)
df$high = ifelse(df$grade %in% grades[c(3,4,5,7,8,12,14,16)],1,0)
```

### Missing years

```{r}
# table of years where free/reduced lunch data is missing
# schools with missing data
missingYears = df$school_no[is.na(df$adm)] %>% unique()

t = df %>%
  filter(school_no %in% missingYears) %>%
  select(school_no, year, adm) %>%
  arrange(school_no, year) %>%
  reshape(idvar = "school_no", timevar = "year", direction = "wide")

colnames(t) = colnames(t) %>% gsub("adm\\.", "", .)
t[,2:9][is.na(t[,2:9])] = ""
t[,2:9][t[,2:9] != ""] = "X"
kable(t)
```

There are some years where we don't have free/reduced lunch price data for schools, but they still seem to be operating. I've emailed KC about this.

## Exploratory Data Analysis

First, let's try to get a sense of the spread of school lunch debt in Durham County.
```{r, fig.width=5, fig.height=3, fig.align="center"}
# normalize debt by adm
df$debt_per_student = df$unpaid/df$adm

hist(df$debt_per_student, main = "", xlab = "debt-per-student")
```
Our data is pretty skewed. If we want to pick up on small differences, it may be worth trying a log transformation.

```{r, fig.width=5, fig.height=3, fig.align="center"}
df$log_dps = log(df$debt_per_student+.01)

hist(df$log_dps, main = "", xlab = "log(debt-per-student)")
```
Alright, much better! Still, our data is bimodal. Let's check if the first node, centered around roughly -4, are years where a school had no debt. These may be years where are school had CEP status.

```{r}
# check CEP status for schools with no debt
df %>%
  filter(unpaid == 0) %>%
  select(school_no, year, cep) %>%
  arrange(school_no, year)
```
For the most part, aside from missing data, it seems like schools with no debt are CEP schools. We can't get CEP status starting in 2010-11, since those were pilot years.

Anyway, I'll stick to the log transformation and continue the EDA.

### Debt and Demographics
```{r, fig.width=12, fig.height=4, fig.align="center"}
# scatterplot of debt vs. pct needy
ggplot(df, aes(pct_needy, debt_per_student)) +
  geom_point() +
  xlab("Percent Needy") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm")

# scatterplot of debt vs. pct black
g1 = ggplot(df, aes(black/adm, debt_per_student)) +
  geom_point() +
  xlab("Percent Black") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm")

# scatterplot of debt vs. pct hispanic
g2 = ggplot(df, aes(hispanic/adm, debt_per_student)) +
  geom_point() +
  xlab("Percent Hispanic") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm")

# scatterplot of debt vs. pct white
g3 = ggplot(df, aes(white/adm, debt_per_student)) +
  geom_point() +
  xlab("Percent White") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm")

plot_grid(g1, g2, g3, ncol = 3)

ggplot(df[], aes((hispanic+black)/adm, debt_per_student)) +
  geom_point(aes(col = cep)) +
  xlab("Percent Minority")

g1 = ggplot(df, aes(white/adm, black/adm)) +
  geom_point() +
  geom_smooth(method = "lm") +
  xlab("Percent White") +
  ylab("Percent Black")

g2 = ggplot(df, aes(white/adm, hispanic/adm)) +
  geom_point() +
  geom_smooth(method = "lm") +
  xlab("Percent White") +
  ylab("Percent Hispanic")

g3 = ggplot(df, aes(black/adm, hispanic/adm)) +
  geom_point() +
  geom_smooth(method = "lm") +
  xlab("Percent Black") +
  ylab("Percent Hispanic")

plot_grid(g1, g2, g3, ncol = 3)
```

Looks like as schools become more black, they also see more debt-per-student. The same trend is there for hispanic students, but less pronounced. And when it comes to white schools, the more white students---the less debt. We're also seeing that schools tend to be segregated---there is a negative correlation between the percentage of black students and and white students, and a slightly less strong, but still negative correlation between the percentage of white and hispanic students. The percentege of black and hispanic students are positively correlated.

### Debt and Locale
```{r, fig.width=8,fig.height=4, fig.align="center"}
# boxplot by urban centric local
ggplot(df, aes(urban_centric_locale, log_dps)) +
  geom_boxplot()
```

Large cities, on average, have less debt than their smaller and more suburban and rural counterparts.

```{r}
# boxplot by grades
elem = df[df$elementary==1,][c("school_no","unpaid","debt_per_student","log_dps")]
elem$grade = "elementary"

mid = df[df$middle==1,][c("school_no","unpaid","debt_per_student","log_dps")]
mid$grade = "middle"

high = df[df$high==1,][c("school_no","unpaid","debt_per_student","log_dps")]
high$grade = "high"

byGrade = rbind(high,mid,elem)

ggplot(byGrade, aes(grade, log_dps)) +
  geom_boxplot()
```

We also see that elementary and high schools tend to have more dept per student than middle schools.

### Longitudinal look at debt from 2010-11 through 2017-18
```{r debt_over_time, fig.width=8, fig.height=4}
# debt by school over time
p1 = ggplot(df, aes(year, unpaid, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("total debt") +
  ggtitle("Total Debt by School") +
  scale_y_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12))

# debt/student over time
p2 = ggplot(df, aes(year, debt_per_student, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("debt per student") +
  ggtitle("Debt per Student by School") +
  scale_y_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12))

plot_grid(p1, p2)
```

There's a lot of fluctuation in total debt and debt-per-student across all schools, so I'll try to find the "most extreme" schools using a few measures. But first, let's take a look at the spread of our data.

```{r}

```


The first is simple: Let's see which schools, on average, have the highest debt.



```{r, fig.width=5, fig.height=3, fig.align="center"}
# calculate mean debt per student
means = df %>%
  group_by(school_no) %>%
  summarise(mean_debt = mean(debt_per_student, na.rm = TRUE)) %>%
  arrange(-mean_debt)

# histogram
hist(means$mean_debt, main = "Histogram of Mean Debt-per-Student", xlab = "Mean Debt-per-Student")
```

The data is not normally distributed. Let's try a log transformation.

```{r, fig.width=5, fig.height=3, fig.align="center"}
# Histogram of log transformation
hist(log(means$mean_debt), main = "Histogram of log(Mean Debt-per-Student)", xlab = "log(Mean Debt-per-Student)")
```

A log transformation makes this data much more normalized. Let's use this to grab find outliers in the data based on Z-scores.


After normalizing the data with a log transformation, there aren't any schools that seem to be outliers in terms of their mean debt-per-student, except for 353 (Middle College High School), which typically has \textit{less} debt than the rest of public schools. What's different about this school?

```{r}
df %>%
  filter(school_no == 353) %>%
  select(year, adm, unpaid, free, reduced, cep)
```

Hm. Seems like we're missing a lot of data. I'll get back to that later.








### Mean and variance of debt within schools

I also looked at the mean and variance of debt per student by school. This gives us a sense of \textit{how} much debt per student fluctuates within in each school. Schools with a high variance should be looked into---perhaps fluctuations in debt are tied to CEP status? Or someone bailing a school out of debt? Similarly, schools with a generally high mean debt per student are of interest. Why are these schools struggling more than others?
```{r histograms, fig.width=8, fig.height=4}
# calculate mean and variance of debt/student by school
sums = df %>%
  group_by(school_no) %>%
  summarise(mean_debt = mean(debt_per_student, na.rm = TRUE),
            var = var(debt_per_student, na.rm = TRUE)) %>%
  arrange(-var)

# histogram of mean debt per student
h1 = ggplot(sums, aes(mean_debt)) +
  geom_histogram() +
  xlab("mean") +
  scale_x_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        plot.margin = margin(2, 0, 2, 2, "cm"))

# histogram of variance of mean debt per student
h2 = ggplot(sums, aes(var)) +
  geom_histogram() +
  xlab("variance") +
  scale_x_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        plot.margin = margin(1, 0, 2, 2, "cm"))

plot_grid(h1, h2,
          labels = c("Mean Debt-per-Student","Within-School Variance"),
          label_size = 12)
```

There are definitely some outliers in our data when it comes to variance of within-school debt per student and mean debt-per-student. Let's pull any schools that fall greater than 2 standard deviations from the mean (proper outliers) and see what their debt-per-student looks like longitudinally.

### High variance schools
```{r high_var, fig.width=12, fig.height=4}
# grab school codes for high variance
high.var = sums$school_no[sums$var > 100]

# debt/student over time
p1 = ggplot(df[df$school_no %in% high.var,], aes(year, debt_per_student, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("Debt-per-Student") +
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12))

# total debt over time
p2 = ggplot(df[df$school_no %in% high.var,], aes(year, unpaid, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("Total Debt") +
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12))


grid = plot_grid(p1 + theme(legend.position = "none"),
          p2 + theme(legend.position = "none"),
          legend = get_legend(p1),
          ncol = 3)

plot_grid(ggdraw() + draw_label("Schools with Most Variance of Debt-per-Student (Var > 100)", size = 12),
          grid, ncol = 1, rel_heights=c(0.1, 1))
```

### Schools with the most debt
```{r mean_debt, fig.width=12, fig.height=4}
# calculate z-scores for mean debt per student
sums$z_debt = scale(sums$mean_debt, center = TRUE, scale = TRUE)

high.debt = sums$school_no[sums$z_debt >= 2]

# z-score greater than 2 is an outlier, plot those schools over time
p1 = ggplot(df[df$school_no %in% high.debt,], aes(year, debt_per_student, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("Debt-per-Student") +
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10))

# z-score greater than 2 is an outlier, plot those schools over time
p2 = ggplot(df[df$school_no %in% high.debt,], aes(year, unpaid, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("Total Debt") + 
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10))

grid = plot_grid(p1 + theme(legend.position = "none"),
          p2 + theme(legend.position = "none"),
          legend = get_legend(p1),
          ncol = 3)

plot_grid(ggdraw() + draw_label("Schools with Outlier Mean Debt-per-Student (Z > 2)", size = 12),
          grid, ncol = 1, rel_heights=c(0.1, 1))
```

### CEP Schools
```{r cep_schools, fig.width=12, fig.height=4}
# grab schools with CEP status at any point in time
cep.schools = df %>%
  group_by(school_no) %>%
  filter(sum(cep, na.rm = TRUE) > 0) %>%
  select(school_no)

cep = df[df$school_no %in% unique(cep.schools$school_no),]

# cep as factor
cep$cep = as.factor(cep$cep)

# debt/student over time
p1 = ggplot(cep, aes(year, debt_per_student, group = school_no)) +
  geom_point(aes(col = cep)) +
  geom_line() +
  ylab("Debt-per-Student") +
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12))

# total debt over time
p2 = ggplot(cep, aes(year, unpaid, group = school_no)) +
  geom_point(aes(col = cep)) +
  geom_line() +
  ylab("Total Debt") +
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12))


grid = plot_grid(p1 + theme(legend.position = "none"),
          p2 + theme(legend.position = "none"),
          legend = get_legend(p1),
          ncol = 3)

plot_grid(ggdraw() + draw_label("CEP Schools", size = 12),
          grid, ncol = 1, rel_heights=c(0.1, 1))

keep = c("2010-11", "2011-12", "2012-13", "2013-14")

ggplot(cep[cep$year %in% keep,], aes((hispanic+black)/adm, debt_per_student)) +
  geom_point(aes(col = cep)) +
  xlab("Percent Minority")

# plot this, but with non-cep schools
# add indicator for longitudinal CEP status
```

NOTES:

- CEP provisions began in 2014-15 in NC
- data collected at different times so numbers won't match perfectly

FOR NEXT WEEK:
- get 2010-11, 2011-12, 2012-13, 2013-14 and 2017-18 CEP data
- fill missing adm/pct needy data (why missing?)
- follow up with James
- add R2, other trend info
- how do students get assigned to schools? any diversity initiatives?

- external factors (paying off debt, CEP status)
  - how to track people paying off debt/dates?
- think about fairly comparing schools
- LONG TERM: can a student graduate with debt? are they barred from anything? what are consequences besides food?