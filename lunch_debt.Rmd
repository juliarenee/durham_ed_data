---
title: "Unpaid Lunch Debt in Durham, NC"
author: "Julia Donheiser"
date: "11/2/2018"
output: pdf_document
urlcolor: blue
---

## Introduction
When families can’t afford to pay for student lunches, school districts foot the bill. But with major cuts to educational funding in North Carolina—where some schools don’t even have enough funds to pay for students’ textbooks—this means school districts can wrack up tens of thousands of dollars in debt. In Durham, students with five or more unpaid lunches only receive a juice and a sandwich instead of a hot lunch. This lends its way to “lunch shaming”, where students who can’t afford pay skip the meal altogether to avoid the embarrassment of eating a cold lunch. This is a major issue, since student performance in school is directly tied to access to quality food.

### Data Sources
* End-of-Year unpaid meal data from James Keaton, director of child nutrition services at DPS.
* All free/reduced price lunch data was obtained from \href{http://www.ncpublicschools.org/fbs/resources/data/}{ncpublicschools.org}
* 2010-11 through 2015-16 demographic data was obtained from the \href{https://nces.ed.gov/ccd/elsi/tableGenerator.aspx}{NCES ELSI table generator}, code 91803
* 2017-18 ADM data from ncpublicschools.org's \href{http://www.ncpublicschools.org/fbs/accounting/data/}{Average Daily Membership and Membership Last Day by School}
* 2016-17, 2017-18 demographic data from \href{https://www.dpsnc.net/site/Default.aspx?PageID=324}{Durham Public Schools}
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, echo = FALSE, message = FALSE)

library(readxl) # read spreadsheets
library(dplyr) # wrangling
library(ggplot2) # graphing
library(tidyr) # reshaping
library(stringr) # string manipulation
library(data.table) # working with tables
library(cowplot) # layout plots
library(pdftools) # pdf to data
library(knitr) # nice tables

# get all older files, .xls format
old.dat = list.files("./data") %>%
  grep("freereduced.xls$", ., value = TRUE)

# read files as table
dat = lapply(paste("./data/",old.dat,sep=""), function(x) read_xls(x))

# clean empty rows
head(dat[[1]])
colnames(dat[[1]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[1]] = dat[[1]][2:dim(dat[[1]])[1],]
head(dat[[2]])
colnames(dat[[2]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[2]] = dat[[2]][5:dim(dat[[2]])[1],]
head(dat[[3]])
colnames(dat[[3]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[3]] = dat[[3]][7:dim(dat[[3]])[1],]
head(dat[[4]])
colnames(dat[[4]]) = c("lea_no","lea_name","school_no","school_name","adm","reduced","free","pct_needy","grade")
dat[[4]] = dat[[4]][7:dim(dat[[4]])[1],]
head(dat[[5]])
colnames(dat[[5]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy","pct_needy_mlt")

# get newer files, .xlsx format
new.dat = list.files("./data") %>%
  grep("freereduced.xlsx$", ., value = TRUE)
dat2 = lapply(paste("./data/",new.dat,sep=""), function(x) read_xlsx(x))

# check for cleaning
head(dat2[[1]])
colnames(dat2[[1]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy","pct_needy_mlt")
head(dat2[[2]])
colnames(dat2[[2]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy")
head(dat2[[3]])
colnames(dat2[[3]]) = c("lea_no","lea_name","school_no","school_name","cep","adm","free","reduced","pct_needy")

# join all data
dat[6:8] = dat2

# transform to data frames
dat = lapply(dat, function(x) data.frame(x))

# remove totals (last row)
dat = lapply(dat, function(x) x[-nrow(x),])

# add id for year
yrs = c(old.dat, new.dat) %>% substr(., 0, 7) # get year to bind as column
for(i in 1:length(dat)) {
  dat[[i]]$year = yrs[i]
}

# merge
df = do.call(plyr::rbind.fill, dat)

# filter to durham county
df = df[grepl("Durham", df$lea_name, ignore.case = TRUE),]

# indicator for CEP data
df$cep = ifelse(is.na(df$cep), 0, 1)

# for reduced < 20, set to 20
df$reduced[grepl("less than", df$reduced, ignore.case = TRUE)] = 20

# recalculate percent needy
df[,c(5:7)] = lapply(df[,c(5:7)],as.numeric)
df$pct_free_reduced = (df$free + df$reduced)/df$adm

# only keep percent needy to avoid conflicting adm
df = df %>% select(c("school_no","school_name","year","pct_free_reduced","adm","cep","grade"))

# load lunch debt data
debt = read.csv("./data/meal_debt.csv")
debt = debt[1:nrow(debt)-1,1:10] # remove totals at bottom, only full year data
colnames(debt)[1:2] = c("school_no", "school_name")
colnames(debt)[3:9] = yrs # reform years
colnames(debt)[10] = "2017-18"

# reshape wide to long
debt = gather(debt, year, unpaid, 3:10)

# convert to integer
debt$unpaid = debt$unpaid %>%
  gsub("\\$","",.) %>%
  gsub("\\,","",.) %>%
  as.numeric()

# convert to factor for joining
df$school_no = as.factor(df$school_no)
debt$school_no = as.factor(debt$school_no)

# join unpaid lunch with free/reduced lunch data
df = left_join(debt, df, by = c("year","school_no"))

# dedupe school name cols
df = df %>% select(-c("school_name.y"))
colnames(df)[which(colnames(df)=="school_name.x")] = "school_name"

# add demographic data
dem = read.csv("./data/nces_demographics.csv")

# remove state, only NC
dem = dem[-c(2)]

# also remove summary rows
spchars = c("†","‡","–")
dem = dem[!grepl(paste(spchars,collapse="|"),dem$School.Name),]

# split to datasets by year
dem11 = dem[c(1, grep("2010\\.11",colnames(dem)))]
dem12 = dem[c(1, grep("2011\\.12",colnames(dem)))]
dem13 = dem[c(1, grep("2012\\.13",colnames(dem)))]
dem14 = dem[c(1, grep("2013\\.14",colnames(dem)))]
dem15 = dem[c(1, grep("2014\\.15",colnames(dem)))]
dem16 = dem[c(1, grep("2015\\.16",colnames(dem)))]

# vectorize
x = list(dem11, dem12, dem13, dem14, dem15, dem16)

# FUNCTION: reformat column names
changeNames = function(z) {
  newNames = colnames(z) %>%
    gsub("\\.+","\\_",.) %>%
    tolower() %>%
    gsub("\\_students.*","",.) %>%
    gsub("\\_public_school.*","",.)
  colnames(z) = newNames
  return(z)
}

# apply to dataframes
x = lapply(x, changeNames)

# add year as variable
for(i in 1:length(x)) {
  x[[i]]$year = yrs[i]
}

# merge to dataframe
dem = do.call(rbind, x)

# set non-numeric values
dem[dem==spchars[1]] = NA
dem[dem==spchars[2]] = NA
dem[dem==spchars[3]] = NA

# all vars as char
dem[,1:14] = lapply(dem[,1:14],as.character)

# set alternative zeros to 0
dem[dem=="=0"] = 0
dem[dem=="=000"] = 0

# filter to durham
dem = dem[grepl("Durham", dem$county_name, ignore.case = TRUE),]

# clean school num
dem$state_school_id[nchar(dem$state_school_id) > 3] = dem$state_school_id[nchar(dem$state_school_id) > 3] %>% substr(., nchar(.)-2, nchar(.))

# vars to numeric
dem[,c(2:10)] = lapply(dem[,c(2:10)],as.numeric)

# calculate percentages
dem$adm = dem$male + dem$female
dem$pct_amin = dem$american_indian_alaska_native/dem$adm
dem$pct_asian = dem$asian_or_asian_pacific_islander/dem$adm
dem$pct_hispanic = dem$hispanic/dem$adm
dem$pct_black = dem$black/dem$adm
dem$pct_haw_pac = dem$hawaiian_nat_pacific_isl/dem$adm
dem$pct_white = dem$white/dem$adm
dem$pct_multi = dem$two_or_more_races/dem$adm

# only keep relevent cols for merging
dem = dem[c(12:14,16:22)]

# change col name
colnames(dem)[which(colnames(dem)=="state_school_id")] = "school_no"

# download durham 16-17, 17-18 demographic data
dem.new = list.files("./data") %>%
  grep("durham_dem", ., value = TRUE)

dem.new = lapply(paste("./data/",dem.new,sep=""), function(x) read_xlsx(x, skip = 2))

# only keep relevent cols
# school code
# and percentages of race
keep = c(2,seq(6,30,4))
dem.new = lapply(dem.new, function(x) x[keep])

# change column names
dem.names = c("school_no",
              "pct_amin",
              "pct_asian",
              "pct_hispanic",
              "pct_black",
              "pct_haw_pac",
              "pct_white",
              "pct_multi")
colnames(dem.new[[1]]) = dem.names
colnames(dem.new[[2]]) = dem.names

# add year
dem.new[[1]]$year = "2016-17"
dem.new[[2]]$year = "2017-18"

# clean school num
dem.new[[1]]$school_no = dem.new[[1]]$school_no %>% substr(., 4, 6)
dem.new[[2]]$school_no = dem.new[[2]]$school_no %>% substr(., 4, 6)

# merge
dem = plyr::rbind.fill(dem, data.frame(dem.new[[1]]), data.frame(dem.new[[2]]))

# merge with df
df = left_join(df, dem, by=c("school_no","year"))

# normalize debt by adm
df$debt_per_student = df$unpaid/df$adm

# standardize locales
df$urban_centric_locale[grepl("City", df$urban_centric_locale)] = "City"
df$urban_centric_locale[grepl("Suburb", df$urban_centric_locale)] = "Suburb"
df$urban_centric_locale[grepl("Rural", df$urban_centric_locale)] = "Rural"

# fill missing years for locale
locales = df %>%
  filter(!is.na(urban_centric_locale)) %>%
  group_by(school_no, urban_centric_locale) %>%
  summarise(count = n()) %>%
  distinct()

# some schools have multiple classifications
# choose the classification with more years
mult.locales = which(table(locales$school_no) > 1) %>% names() # schools that have more than 1 locale in data
for(i in 1:length(mult.locales)) {
  ix = which(locales$school_no == mult.locales[i]) # indeces
  m = min(locales$count[ix[1]], locales$count[ix[2]]) # minimums
  locales = locales[-ix[m],] # remove
}

# locales as list
locales.list = locales$urban_centric_locale
names(locales.list) = locales$school_no

# impute locales
df$urban_centric_locale = locales.list[df$school_no]

# many schools started offering Pre-K
# ignore this for now since only interested in elementary, middle and high schools
# replace Pre-K with K for consistency
df$grade = df$grade %>%
  trimws(.) %>% # trim trailing white space
  gsub("Pre-K","K",.) %>% # replace Pre-K
  gsub("[[:blank:]]+\\-[[:blank:]]+","\\-",.) %>% # remove space between dashes
  gsub("[[:blank:]]+","-",.) %>% # add dash for consistency
  gsub("0","",.) # remove 0 before single digit grades
  
# see schools with more than 1 grade entry
g = df %>%
  filter(!is.na(grade)) %>%
  select(school_no, grade) %>%
  distinct() %>%
  group_by(school_no) %>%
  mutate(occ = n()) %>%
  filter(occ > 1)

grades = unique(df$grade)

# indicator for elementary school
df$elementary = ifelse(df$grade %in% grades[c(1,5,9,11,13,14,15,16,18)], 1, 0)
df$middle = ifelse(df$grade %in% grades[c(2,4,5,10,14,16,17)],1,0)
df$high = ifelse(df$grade %in% grades[c(3,4,5,7,8,12,14,16)],1,0)

# table of years where free/reduced lunch data is missing
# schools with missing data
missing = df$school_name[is.na(df$adm)] %>% unique()
missing

# remove DPS hospital school 
df = df[-which(df$school_name=="DPS Hospital School"),]

# remove 389, 700 since no longer active
df = df[-which(df$school_no %in% c(389, 700)),]

# 353 housed in Durham tech, to remove or not?
missing = df$school_name[is.na(df$adm)] %>% unique()
missing

# and grades for missing years
```

## Exploratory Data Analysis
```{r, fig.width=5, fig.height=3, fig.align="center"}
# histogram
hist(df$debt_per_student, main = "", xlab = "debt-per-student")
```
Most schools have less than \$5 of lunch debt per student. In Durham, a full-priced lunch costs \$2.90, and a reduced-price lunch cost \$0.40, according to the Durham Public Schools \href{https://www.dpsnc.net/site/handlers/filedownload.ashx?moduleinstanceid=196&dataid=173&FileName=2018-19%20FR%20Lunch%20App_Eng.pdf}{website}. That's about two unpaid full-priced lunches per student, or just over 12 unpaid reduced-price lunches per student. For the rest of my EDA, I'll delve into which schools have more debt and whether we can find systematic issues. I'll also be looking at schools that are part of the Community Eligibility Provision, which means all students receive free lunch.

### CEP Status
```{r cep_schools, fig.width=12, fig.height=4}
# grab schools with CEP status at any point in time
cep.schools = df %>%
  group_by(school_no) %>%
  summarise(years_cep = sum(cep, na.rm = TRUE)) %>%
  filter(years_cep > 0)

# indicator for whether school has had CEP at any point in time
# as of current, CEP var is on a yearly basis
df$cep_long = 0
df$cep_long[df$school_no %in% cep.schools$school_no] = 1

# longitudinal as factor
df$cep_long = as.factor(df$cep_long)

# CEP status as factor
df$cep = as.factor(df$cep)
```

### Debt and Demographics
```{r, fig.width=12, fig.height=4, fig.align="center"}
# scatterplot of debt vs. pct needy
ggplot(df, aes(pct_free_reduced, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("percent students with free and reduced lunch") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

# scatterplot of debt vs. pct black
g1 = ggplot(df, aes(pct_black, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("Percent Black") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

# scatterplot of debt vs. pct hispanic
g2 = ggplot(df, aes(pct_hispanic, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("Percent Hispanic") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

# scatterplot of debt vs. pct white
g3 = ggplot(df, aes(pct_white, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("Percent White") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

plot_grid(g1, g2, g3, ncol = 3)

ggplot(df, aes(pct_black+pct_hispanic, debt_per_student)) +
  geom_point(aes(col = cep_long)) +
  xlab("Percent Minority") +
  ylab("debt-per-student") +
  geom_smooth(method = "lm", se = FALSE)

g1 = ggplot(df, aes(pct_white, pct_black)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent White") +
  ylab("Percent Black")

g2 = ggplot(df, aes(pct_white, pct_hispanic)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent White") +
  ylab("Percent Hispanic")

g3 = ggplot(df, aes(pct_black, pct_hispanic)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent Black") +
  ylab("Percent Hispanic")

plot_grid(g1, g2, g3, ncol = 3)
```

There is a weak positive correlation between the percentage of students who have free and reduced price lunch and the debt-per-student at each school. It looks like schools with CEP status generally have a higher percentage of students on free/reduced lunch. As for demographics, there is also a weak positive correlation between the percentage of black students and debt-per-student. Conversely, there is a weak negative correlation between the percent of white students and debt-per-student. There doesn't appear to be a much of a relationship between the percentage of hispanic students and debt-per-student. That being said, if we look at the total percentage of minority students --- the percentage of black \textit{and} hispanic students --- there is a positive correlation with debt-per-student. Schools that CEP status are also starkly segregated, with very few white students and primarily black and hispanic students.

### Debt over time
```{r debt_over_time, fig.width=8, fig.height=4}
# debt by school over time
p1 = ggplot(df, aes(year, unpaid, group = school_no, col = cep_long)) +
  geom_point() +
  geom_line() +
  ylab("total debt") +
  ggtitle("Total Debt by School") +
  scale_y_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12)) +
  facet_wrap(~ cep_long, nrow = 2)

# debt/student over time
p2 = ggplot(df, aes(year, debt_per_student, group = school_no, col = cep_long)) +
  geom_point() +
  geom_line() +
  ylab("debt per student") +
  ggtitle("Debt per Student by School") +
  scale_y_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12)) +
  facet_wrap(~ cep_long, nrow = 2)

plot_grid(p1, p2)
```

Schools with CEP status generally had a large amount of debt until the 2014-15 school year, when they gained CEP status. That being said, other schools with similar amounts of debt did not gain CEP status.

### Demographics and need
```{r, fig.width=12, fig.height=4, fig.align="center"}
g1 = ggplot(df, aes(pct_white, pct_free_reduced)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent White") +
  ylab("percent students with free and reduced lunch")

g2 = ggplot(df, aes(pct_hispanic, pct_free_reduced)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent Hispanic") +
  ylab("percent students with free and reduced lunch")

g3 = ggplot(df, aes(pct_black, pct_free_reduced)) +
  geom_point(aes(col = cep_long)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Percent Black") +
  ylab("percent students with free and reduced lunch")

plot_grid(g1, g2, g3, ncol = 3)
```

We can also see that race is a proxy for need. The percentage of black and hispanic schools have a strong, positive correlation with the percentage of students on free and reduced price lunch. For white students, this relationship is strong and negative.

### Locale and debt, race
```{r, fig.width=12, fig.height=4, fig.align="center"}
b1 = ggplot(df, aes(urban_centric_locale, unpaid)) +
  geom_boxplot()

b2 = ggplot(df, aes(urban_centric_locale, debt_per_student)) +
  geom_boxplot()

plot_grid(b1, b2, ncol = 2)
```
There don't seem to be major differences in debt by location.

```{r, fig.width=12, fig.height=4, fig.align="center"}
b1 = ggplot(df, aes(urban_centric_locale, pct_white)) +
  geom_boxplot() +
  ylim(c(0,1))

b2 = ggplot(df, aes(urban_centric_locale, pct_black)) +
  geom_boxplot() +
  ylim(c(0,1))

b3 = ggplot(df, aes(urban_centric_locale, pct_hispanic)) +
  geom_boxplot() +
  ylim(c(0,1))

plot_grid(b1, b2, b3, ncol = 3)
```
On average, we also don't see any major differences in race by locale. However, there is a subset of rural schools that seem to primarily be white.

### Debt and grade

## Regression

Now, I'll try to predict total debt based on demographic factors and percent needy students. For this, I'll set schools with more than 100% free and reduced price lunch to just 100%, since those schools have completely free lunches.

### Predicting debt with demographics
```{r}
# predict debt by demographics
lm.dem = lm(debt_per_student ~ pct_white + pct_black + pct_hispanic, data = df[df$cep == 0,])
summary(lm.dem)

# residuals
plot(lm.dem$residuals)
```

### Predicting debt with need
```{r}
# predict debt by percent need
lm.need = lm(debt_per_student ~ pct_free_reduced, data = df[df$cep == 0,])
summary(lm.need)

# residuals
plot(lm.need$residuals)
```


There's a lot of fluctuation in total debt and debt-per-student across all schools, so I'll try to find the "most extreme" schools using a few measures. But first, let's take a look at the spread of our data.

### Mean and variance of debt within schools

I also looked at the mean and variance of debt per student by school. This gives us a sense of \textit{how} much debt per student fluctuates within in each school. Schools with a high variance should be looked into---perhaps fluctuations in debt are tied to CEP status? Or someone bailing a school out of debt? Similarly, schools with a generally high mean debt per student are of interest. Why are these schools struggling more than others?
```{r histograms, fig.width=8, fig.height=4}
# calculate mean and variance of debt/student by school
sums = df %>%
  group_by(school_no) %>%
  summarise(mean_debt = mean(debt_per_student, na.rm = TRUE),
            var = var(debt_per_student, na.rm = TRUE)) %>%
  arrange(-var)

# histogram of mean debt per student
h1 = ggplot(sums, aes(mean_debt)) +
  geom_histogram() +
  xlab("mean") +
  scale_x_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        plot.margin = margin(2, 0, 2, 2, "cm"))

# histogram of variance of mean debt per student
h2 = ggplot(sums, aes(var)) +
  geom_histogram() +
  xlab("variance") +
  scale_x_continuous(labels = scales::dollar) +
  theme(legend.position = "none",
        plot.margin = margin(1, 0, 2, 2, "cm"))

plot_grid(h1, h2,
          labels = c("Mean Debt-per-Student","Within-School Variance"),
          label_size = 12)
```

There are definitely some outliers in our data when it comes to variance of within-school debt per student and mean debt-per-student. Let's pull any schools that fall greater than 2 standard deviations from the mean (proper outliers) and see what their debt-per-student looks like longitudinally.

### High variance schools
```{r high_var, fig.width=12, fig.height=4}
# grab school codes for high variance
high.var = sums$school_no[sums$var > 100]

# debt/student over time
p1 = ggplot(df[df$school_no %in% high.var,], aes(year, debt_per_student, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("Debt-per-Student") +
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12))

# total debt over time
p2 = ggplot(df[df$school_no %in% high.var,], aes(year, unpaid, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("Total Debt") +
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10),
        axis.title.x = element_blank(),
        plot.title = element_text(size = 12))


grid = plot_grid(p1 + theme(legend.position = "none"),
          p2 + theme(legend.position = "none"),
          legend = get_legend(p1),
          ncol = 3)

plot_grid(ggdraw() + draw_label("Schools with Most Variance of Debt-per-Student (Var > 100)", size = 12),
          grid, ncol = 1, rel_heights=c(0.1, 1))
```

### Schools with the most debt
```{r mean_debt, fig.width=12, fig.height=4}
# calculate z-scores for mean debt per student
sums$z_debt = scale(sums$mean_debt, center = TRUE, scale = TRUE)

high.debt = sums$school_no[sums$z_debt >= 2]

# z-score greater than 2 is an outlier, plot those schools over time
p1 = ggplot(df[df$school_no %in% high.debt,], aes(year, debt_per_student, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("Debt-per-Student") +
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10))

# z-score greater than 2 is an outlier, plot those schools over time
p2 = ggplot(df[df$school_no %in% high.debt,], aes(year, unpaid, group = school_no, col = school_no)) +
  geom_point() +
  geom_line() +
  ylab("Total Debt") + 
  scale_y_continuous(labels = scales::dollar) +
  scale_fill_manual(labels = names) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10))

grid = plot_grid(p1 + theme(legend.position = "none"),
          p2 + theme(legend.position = "none"),
          legend = get_legend(p1),
          ncol = 3)

plot_grid(ggdraw() + draw_label("Schools with Outlier Mean Debt-per-Student (Z > 2)", size = 12),
          grid, ncol = 1, rel_heights=c(0.1, 1))
```

NOTES:

- CEP provisions began in 2014-15 in NC
- data collected at different times so numbers won't match perfectly
- 353 is housed in Durham Tech, which complicates some of the data
- For the most part, aside from missing data, it seems like schools with no debt are CEP schools. We can't get CEP status starting in 2010-11, since those were pilot years.
- CEP schools for 2017-18 all have > 90% free/reduced, setting to 100% (doesn't affect analysis since excluded from regression)


REPORTING QUESTIONS:
- how do students get assigned to schools? any diversity initiatives?
- does the district track when debt is payed off?
- can a student graduate with debt? are they barred from anything? what are consequences besides food?